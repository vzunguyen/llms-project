# Project Brief
This project is based on the workshop [Building LLMs from the Ground Up: A 3-hour Coding Workshop](https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up). It is my first exploration into building a language model from scratch.

## Project Overview
The goal of this project is to understand the inner workings of large language models (LLMs) by implementing one from the ground up.

## Project Progress
-[x] Data Processing
-[x] Data Set, Data Load
-[x] GPT architecture
    -[x] Multihead Attention
    -[x] Layer Norm
    -[x] GELU
    -[x] Feed Forward
    -[x] Transformer Block
-[x] Generating new text (Untrained)

## Technology being used in LLM Project

# References
[Building LLMs from the Ground Up: A 3-hour Coding Workshop](https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up)

Apart from "Building LLMs from the Ground Up: A 3-hour Coding Workshop", [Create a Large Language Model from Scratch with Python â€“ Tutorial](https://www.youtube.com/watch?v=UU1WVnMk4E8) was also used to help with developing the project.

***This project is developed by Zu***